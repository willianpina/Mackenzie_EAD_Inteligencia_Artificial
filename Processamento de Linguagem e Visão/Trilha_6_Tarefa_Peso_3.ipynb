{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><b>DEEP LEARNING PARA PROCESSAMENTO DE LINGUAGEM E VISÃO</b></p>\n",
    "<p align=\"justify\"><b>Turma 1B - 2022/1</b></p>\n",
    "<p><b>Trilha 6:</b> Tarefa (Peso 3)</p>\n",
    "<p></p>\n",
    "<p align='justify'>A mineração de textos é uma das principais atividades do processamento de linguagem natural. Diferentes domínios podem construir aplicações para entender melhor os dados textuais, como grandes portais jornalísticos, que constroem sistemas inteligentes para categorizar notícias.</p>\n",
    "<p align='center'><img src=https://dhg1h5j42swfq.cloudfront.net/2021/05/11111019/image-255.png></p>\n",
    "<p align='justify'>Nesta tarefa, você deverá desenvolver um categorizador de notícias utilizando redes neurais recorrentes. Para isso, utilize o conjunto de dados <i>Reuters</i> presente nativamente no TensorFlow-Keras.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import reuters\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de rótulos: 46\n"
     ]
    }
   ],
   "source": [
    "# Total de Labels\n",
    "total_labels = len(np.unique(y_train))\n",
    "print(f'Total de rótulos: {total_labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW:  the of of mln loss for plc said at only ended said commonwealth could 1 traders now april 0 a after said from 1985 and from foreign 000 april 0 prices its account year a but in this mln home an states ...\n",
      "LABEL :  3 \n",
      "\n",
      "REVIEW:  the of of mln loss for plc said at only ended said commonwealth could 1 traders now april 0 a after said from 1985 and from foreign 000 april 0 prices its account year a but in this mln home an states ...\n",
      "LABEL :  3 \n",
      "\n",
      "REVIEW:  the termination payment airport takes 6 of geological 3 6 602 begin up said fully bank expects commodity total is giant a of this takes of series termination payment airport mln a for capital 1 pre 50 ...\n",
      "LABEL :  4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recuperando os índices de mapeamento {dict} para seu índice no conjunto de dados do reuters.\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "# Percorrendo o dicionário word_index e recuparando cada palavra com seu respectivo índice.\n",
    "index_to_word = {}\n",
    "\n",
    "for key, value in word_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "# Imprimindo apenas alguns exemplos de Reviews com seus respectivos Labels\n",
    "frases = []\n",
    "for i in range(2):\n",
    "    frase = ' '.join([index_to_word[x] for x in X_train[i]])\n",
    "    frases.append(frase)\n",
    "    for review, label in zip(frases, y_train):\n",
    "        print('REVIEW: ', review[:200], \"...\")\n",
    "        print('LABEL : ', label, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessando o conjunto de dados \n",
    "max_words = 10000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "X_train = tokenizer.sequences_to_matrix(X_train, mode='binary')\n",
    "X_test = tokenizer.sequences_to_matrix(X_test, mode='binary')\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, total_labels)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, total_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "253/253 [==============================] - 6s 24ms/step - loss: 1.2788 - accuracy: 0.7219 - val_loss: 0.9574 - val_accuracy: 0.7920\n",
      "Epoch 2/5\n",
      "253/253 [==============================] - 6s 24ms/step - loss: 0.4793 - accuracy: 0.8908 - val_loss: 0.8443 - val_accuracy: 0.8131\n",
      "Epoch 3/5\n",
      "253/253 [==============================] - 6s 25ms/step - loss: 0.2922 - accuracy: 0.9352 - val_loss: 0.8611 - val_accuracy: 0.8187\n",
      "Epoch 4/5\n",
      "253/253 [==============================] - 6s 24ms/step - loss: 0.2171 - accuracy: 0.9480 - val_loss: 0.9925 - val_accuracy: 0.8009\n",
      "Epoch 5/5\n",
      "253/253 [==============================] - 6s 24ms/step - loss: 0.1984 - accuracy: 0.9529 - val_loss: 0.9625 - val_accuracy: 0.8065\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.9438 - accuracy: 0.8068\n",
      "Perda: 0.9437685012817383\n",
      "Acurácia: 0.8067675828933716\n"
     ]
    }
   ],
   "source": [
    "# Construindo um Modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(total_labels))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Compilando\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "# Ajustando o Modelo\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.1)\n",
    "\n",
    "# Avaliando o Modelo\n",
    "score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('Perda:', score[0])\n",
    "print('Acurácia:', score[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "adc9bb8b32507af041d48f79beff297e5596f2d08c3fa998d68427d7acb13fb8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
